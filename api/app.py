from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import os
import uuid
import joblib
import librosa
import numpy as np
import uvicorn
import sys
import logging
import json
from datetime import datetime

# ë¡œê¹… ì„¤ì • - ë” ìƒì„¸í•œ í¬ë§·
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('feature_extraction.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš©, ë°°í¬ì‹œì—ëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ë¡œë“œ (ë‹¨ìˆœ pkl íŒŒì¼)
model = joblib.load("watermelon_sound_rf.pkl")

def log_audio_info(y, sr, file_path):
    """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ê¸°ë³¸ ì •ë³´ë¥¼ ë¡œê¹…"""
    duration = len(y) / sr
    max_amplitude = np.max(np.abs(y))
    rms_energy = np.sqrt(np.mean(y**2))
    
    logger.info(f"ğŸ“ íŒŒì¼ ì •ë³´: {os.path.basename(file_path)}")
    logger.info(f"   - ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sr} Hz")
    logger.info(f"   - ê¸¸ì´: {duration:.2f}ì´ˆ ({len(y)} ìƒ˜í”Œ)")
    logger.info(f"   - ìµœëŒ€ ì§„í­: {max_amplitude:.6f}")
    logger.info(f"   - RMS ì—ë„ˆì§€: {rms_energy:.6f}")
    logger.info(f"   - ë‹¤ì´ë‚˜ë¯¹ ë ˆì¸ì§€: {20 * np.log10(max_amplitude / (rms_energy + 1e-8)):.2f} dB")

def log_feature_details(feature_name, feature_data, feature_mean):
    """ê°œë³„ íŠ¹ì„±ì˜ ìƒì„¸ ì •ë³´ë¥¼ ë¡œê¹…"""
    logger.info(f"ğŸ” {feature_name} ë¶„ì„:")
    logger.info(f"   - ì›ë³¸ shape: {feature_data.shape}")
    logger.info(f"   - í‰ê· ê°’ shape: {feature_mean.shape}")
    logger.info(f"   - ê°’ ë²”ìœ„: [{np.min(feature_data):.6f}, {np.max(feature_data):.6f}]")
    logger.info(f"   - í‰ê· ê°’ ë²”ìœ„: [{np.min(feature_mean):.6f}, {np.max(feature_mean):.6f}]")
    logger.info(f"   - í‘œì¤€í¸ì°¨: {np.std(feature_data):.6f}")
    
    # ê° ê³„ìˆ˜ë³„ ìƒì„¸ ì •ë³´ (MFCC, Chromaë§Œ)
    if feature_name in ["MFCC", "Chroma"]:
        logger.info(f"   - ê³„ìˆ˜ë³„ í‰ê· ê°’:")
        for i, val in enumerate(feature_mean):
            logger.info(f"     [{i+1:2d}] {val:10.6f}")

def log_feature_statistics(features, feature_names):
    """ì „ì²´ íŠ¹ì„±ì˜ í†µê³„ ì •ë³´ë¥¼ ë¡œê¹…"""
    logger.info(f"ğŸ“Š ì „ì²´ íŠ¹ì„± í†µê³„:")
    logger.info(f"   - ì´ íŠ¹ì„± ìˆ˜: {len(features)}")
    logger.info(f"   - ê°’ ë²”ìœ„: [{np.min(features):.6f}, {np.max(features):.6f}]")
    logger.info(f"   - í‰ê· : {np.mean(features):.6f}")
    logger.info(f"   - í‘œì¤€í¸ì°¨: {np.std(features):.6f}")
    logger.info(f"   - ì¤‘ê°„ê°’: {np.median(features):.6f}")
    
    # íŠ¹ì„± ê·¸ë£¹ë³„ í†µê³„
    mfcc_features = features[:13]
    chroma_features = features[13:25]
    other_features = features[25:]
    
    logger.info(f"   - MFCC ê·¸ë£¹ (1-13): í‰ê· ={np.mean(mfcc_features):.6f}, í‘œì¤€í¸ì°¨={np.std(mfcc_features):.6f}")
    logger.info(f"   - Chroma ê·¸ë£¹ (14-25): í‰ê· ={np.mean(chroma_features):.6f}, í‘œì¤€í¸ì°¨={np.std(chroma_features):.6f}")
    logger.info(f"   - ê¸°íƒ€ ê·¸ë£¹ (26-{len(features)}): í‰ê· ={np.mean(other_features):.6f}, í‘œì¤€í¸ì°¨={np.std(other_features):.6f}")

def save_features_to_json(features, feature_names, file_path):
    """íŠ¹ì„±ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
    try:
        feature_data = {
            "timestamp": datetime.now().isoformat(),
            "source_file": os.path.basename(file_path),
            "feature_count": len(features),
            "features": {
                name: float(value) for name, value in zip(feature_names, features)
            },
            "statistics": {
                "min": float(np.min(features)),
                "max": float(np.max(features)),
                "mean": float(np.mean(features)),
                "std": float(np.std(features)),
                "median": float(np.median(features))
            }
        }
        
        json_filename = f"features_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(feature_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ íŠ¹ì„± ë°ì´í„° ì €ì¥ë¨: {json_filename}")
        
    except Exception as e:
        logger.warning(f"íŠ¹ì„± JSON ì €ì¥ ì‹¤íŒ¨: {e}")

def extract_features(file_path, sr=22050, n_mfcc=13):
    """
    ë‹¨ìˆœ ëª¨ë¸ì— ë§ì¶° 27ê°œ íŠ¹ì„± ì¶”ì¶œ (ìƒì„¸ ë””ë²„ê¹… í¬í•¨)
    - MFCC: 13ê°œ
    - Chroma: 12ê°œ  
    - Zero Crossing Rate: 1ê°œ
    - Spectral Centroid: 1ê°œ
    """
    try:
        logger.info(f"ğŸµ íŠ¹ì„± ì¶”ì¶œ ì‹œì‘: {os.path.basename(file_path)}")
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ
        y, sr = librosa.load(file_path, sr=sr)
        log_audio_info(y, sr, file_path)
        
        # 1. MFCC (13ê°œ)
        logger.info("ğŸ”„ MFCC ê³„ì‚° ì¤‘...")
        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)
        mfcc_mean = np.mean(mfcc, axis=1)
        log_feature_details("MFCC", mfcc, mfcc_mean)
        
        # 2. Chroma (12ê°œ)
        logger.info("ğŸ”„ Chroma ê³„ì‚° ì¤‘...")
        chroma = librosa.feature.chroma_stft(y=y, sr=sr)
        chroma_mean = np.mean(chroma, axis=1)
        log_feature_details("Chroma", chroma, chroma_mean)
        
        # 3. Zero Crossing Rate (1ê°œ)
        logger.info("ğŸ”„ Zero Crossing Rate ê³„ì‚° ì¤‘...")
        zcr = librosa.feature.zero_crossing_rate(y)
        zcr_mean = np.mean(zcr)
        logger.info(f"ğŸ” ZCR ë¶„ì„:")
        logger.info(f"   - ì›ë³¸ shape: {zcr.shape}")
        logger.info(f"   - í‰ê· ê°’: {zcr_mean:.6f}")
        logger.info(f"   - ê°’ ë²”ìœ„: [{np.min(zcr):.6f}, {np.max(zcr):.6f}]")
        
        # 4. Spectral Centroid (1ê°œ)
        logger.info("ğŸ”„ Spectral Centroid ê³„ì‚° ì¤‘...")
        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)
        spec_cent_mean = np.mean(spec_cent)
        logger.info(f"ğŸ” Spectral Centroid ë¶„ì„:")
        logger.info(f"   - ì›ë³¸ shape: {spec_cent.shape}")
        logger.info(f"   - í‰ê· ê°’: {spec_cent_mean:.6f}")
        logger.info(f"   - ê°’ ë²”ìœ„: [{np.min(spec_cent):.6f}, {np.max(spec_cent):.6f}]")
        logger.info(f"   - Hz ë‹¨ìœ„: {spec_cent_mean:.2f} Hz")
        
        # ëª¨ë“  íŠ¹ì„± í•©ì¹˜ê¸°
        features = np.concatenate([mfcc_mean, chroma_mean, [zcr_mean], [spec_cent_mean]])
        
        # ì‹¤ì œ íŠ¹ì„± ê°œìˆ˜ í™•ì¸
        logger.info(f"ğŸ” íŠ¹ì„± ê°œìˆ˜ í™•ì¸:")
        logger.info(f"   - MFCC: {len(mfcc_mean)}ê°œ")
        logger.info(f"   - Chroma: {len(chroma_mean)}ê°œ")
        logger.info(f"   - ZCR: 1ê°œ")
        logger.info(f"   - Spectral Centroid: 1ê°œ")
        logger.info(f"   - ì´ íŠ¹ì„± ê°œìˆ˜: {len(features)}ê°œ")
        
        # íŠ¹ì„± ê²€ì¦ (ì‹¤ì œ ê°œìˆ˜ì— ë§ì¶° ì¡°ì •)
        expected_features = len(features)
        assert features.shape[0] == expected_features, f"ì˜ˆìƒ íŠ¹ì„± ìˆ˜: {expected_features}ê°œ, ì‹¤ì œ: {features.shape[0]}ê°œ"
        
        # íŠ¹ì„± ì´ë¦„ ì •ì˜ (ì‹¤ì œ ê°œìˆ˜ì— ë§ì¶°)
        feature_names = (
            [f"mfcc_{i+1}" for i in range(len(mfcc_mean))] +
            [f"chroma_{i+1}" for i in range(len(chroma_mean))] +
            ["zcr"] +
            ["spectral_centroid"]
        )
        
        # ì „ì²´ íŠ¹ì„± í†µê³„
        log_feature_statistics(features, feature_names)
        
        # íŠ¹ì„± ìƒì„¸ ë¡œê¹…
        logger.info(f"ğŸ“‹ === ì¶”ì¶œëœ {len(features)}ê°œ íŠ¹ì„± ìƒì„¸ ===")
        for i, (name, value) in enumerate(zip(feature_names, features)):
            status = "âš ï¸ " if np.isnan(value) or np.isinf(value) else "âœ… "
            logger.info(f"  {status}[{i+1:2d}] {name:20s}: {value:12.6f}")
        
        # NaN/Inf í™•ì¸
        nan_count = np.sum(np.isnan(features))
        inf_count = np.sum(np.isinf(features))
        if nan_count > 0 or inf_count > 0:
            logger.error(f"âŒ íŠ¹ì„± í’ˆì§ˆ ì´ìŠˆ ë°œê²¬!")
            logger.error(f"   - NaN ê°œìˆ˜: {nan_count}ê°œ")
            logger.error(f"   - Inf ê°œìˆ˜: {inf_count}ê°œ")
            
            # ë¬¸ì œê°€ ìˆëŠ” íŠ¹ì„± ì°¾ê¸°
            for i, (name, value) in enumerate(zip(feature_names, features)):
                if np.isnan(value) or np.isinf(value):
                    logger.error(f"   - ë¬¸ì œ íŠ¹ì„±: [{i+1}] {name} = {value}")
        else:
            logger.info("âœ… ëª¨ë“  íŠ¹ì„±ì´ ì •ìƒì…ë‹ˆë‹¤")
        
        # íŠ¹ì„± ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì €ì¥
        save_features_to_json(features, feature_names, file_path)
        
        logger.info(f"ğŸ¯ íŠ¹ì„± ì¶”ì¶œ ì™„ë£Œ: {os.path.basename(file_path)}")
        logger.info("=" * 80)
        
        return features.reshape(1, -1)
        
    except Exception as e:
        logger.error(f"âŒ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {file_path}")
        logger.error(f"   - ì˜¤ë¥˜: {e}")
        logger.error("=" * 80)
        raise

# ë””ë²„ê¹…ìš© íŠ¹ì„± ë¶„ì„ API ì¶”ê°€
@app.post("/debug-features")
async def debug_features(file: UploadFile = File(...)):
    """íŠ¹ì„± ì¶”ì¶œ ë””ë²„ê¹… ì „ìš© API"""
    temp_path = None
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
        ext = os.path.splitext(file.filename)[-1].lower()
        if ext not in [".wav", ".m4a", ".mp3"]:
            return JSONResponse(
                status_code=400, 
                content={"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}
            )

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = f"debug_{uuid.uuid4()}{ext}"
        with open(temp_path, "wb") as f:
            f.write(await file.read())
        
        # íŠ¹ì„± ì¶”ì¶œ (ë””ë²„ê¹… ë¡œê·¸ì™€ í•¨ê»˜)
        features = extract_features(temp_path)
        
        # íŠ¹ì„± ì´ë¦„ ì •ì˜
        feature_names = (
            [f"mfcc_{i+1}" for i in range(13)] +
            [f"chroma_{i+1}" for i in range(12)] +
            ["zcr"] +
            ["spectral_centroid"]
        )
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "success": True,
            "filename": file.filename,
            "feature_count": len(features[0]),
            "features": {
                name: float(value) for name, value in zip(feature_names, features[0])
            },
            "statistics": {
                "min": float(np.min(features)),
                "max": float(np.max(features)),
                "mean": float(np.mean(features)),
                "std": float(np.std(features)),
                "median": float(np.median(features))
            },
            "quality_check": {
                "nan_count": int(np.sum(np.isnan(features))),
                "inf_count": int(np.sum(np.isinf(features))),
                "is_valid": bool(np.all(np.isfinite(features)))
            }
        }
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return JSONResponse(
            status_code=500, 
            content={"error": f"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

# ì„œë²„ ìƒíƒœ í™•ì¸ (Swift ì•±ì—ì„œ ì—°ê²° í…ŒìŠ¤íŠ¸ìš©)
@app.get("/health")
def health_check():
    return {"status": "healthy", "message": "ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤"}

# ì˜ˆì¸¡ API
@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    temp_path = None
    try:
        # íŒŒì¼ í™•ì¥ì ê²€ì‚¬
        ext = os.path.splitext(file.filename)[-1].lower()
        if ext not in [".wav", ".m4a", ".mp3"]:
            return JSONResponse(
                status_code=400, 
                content={
                    "success": False,
                    "error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .wav, .m4a, .mp3 íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
                }
            )

        # ì„ì‹œ íŒŒì¼ ì €ì¥
        temp_path = f"temp_{uuid.uuid4()}{ext}"
        with open(temp_path, "wb") as f:
            f.write(await file.read())
        
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} -> {temp_path}")

        # íŠ¹ì„± ì¶”ì¶œ ë° ì˜ˆì¸¡
        features = extract_features(temp_path)
        
        # ì˜ˆì¸¡ (ìŠ¤ì¼€ì¼ëŸ¬ ì—†ìŒ)
        prediction = model.predict(features)[0]
        probability = model.predict_proba(features)[0] if hasattr(model, 'predict_proba') else None
        
        logger.info(f"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼: {prediction} ({'ë†’ìŒ' if prediction == 1 else 'ë‚®ìŒ'})")
        if probability is not None:
            logger.info(f"   - í™•ë¥ : ë‚®ìŒ={probability[0]:.3f}, ë†’ìŒ={probability[1]:.3f}")
        
        # ê²°ê³¼ ë°˜í™˜
        result = {
            "success": True,
            "filename": file.filename,
            "prediction": int(prediction),
            "result": "ë†’ìŒ" if prediction == 1 else "ë‚®ìŒ",
            "confidence": float(max(probability)) if probability is not None else None
        }
        
        return JSONResponse(content=result)
        
    except Exception as e:
        logger.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return JSONResponse(
            status_code=500, 
            content={
                "success": False,
                "error": f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
        )
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
                logger.info(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_path}")
            except Exception as e:
                logger.warning(f"ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")

# ì§€ì›ë˜ëŠ” íŒŒì¼ í˜•ì‹ ì •ë³´
@app.get("/supported-formats")
def get_supported_formats():
    return {
        "formats": [".wav", ".m4a", ".mp3"],
        "description": "ì§€ì›ë˜ëŠ” ì˜¤ë””ì˜¤ íŒŒì¼ í˜•ì‹"
    }

# íŠ¹ì„± ì •ë³´ API (ë””ë²„ê¹…ìš©)
@app.get("/feature-info")
def get_feature_info():
    return {
        "total_features": 27,
        "feature_groups": {
            "mfcc": {"count": 13, "description": "Mel-frequency cepstral coefficients"},
            "chroma": {"count": 12, "description": "Chroma features"},
            "zcr": {"count": 1, "description": "Zero crossing rate"},
            "spectral_centroid": {"count": 1, "description": "Spectral centroid"}
        },
        "model_type": "DecisionTreeClassifier",
        "classes": ["ë‚®ìŒ", "ë†’ìŒ"]
    }
if __name__ == "__main__":
    import socket
    
    def get_local_ip():
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            ip = s.getsockname()[0]
            s.close()
            return ip
        except:
            return "127.0.0.1"
    
    local_ip = get_local_ip()
    print(f"ğŸ‰ ìˆ˜ë°• ë‹¹ë„ ì˜ˆì¸¡ ì„œë²„ ì‹œì‘")
    print(f"   - ë¡œì»¬: http://localhost:8000")
    print(f"   - ë„¤íŠ¸ì›Œí¬: http://{local_ip}:8000")
    print(f"   - ìƒíƒœ í™•ì¸: http://{local_ip}:8000/health")
    print(f"   - íŠ¹ì„± ë””ë²„ê¹…: http://{local_ip}:8000/debug-features")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)