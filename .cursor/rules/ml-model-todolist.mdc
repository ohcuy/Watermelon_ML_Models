# 🍉 전통적인 ML 모델 기반 수박 당도 예측 프로젝트 - Todo List

## 📋 프로젝트 개요

수박 소리 데이터를 활용하여 **그래디언트 부스팅 트리(GBT)**, **서포트 벡터 머신(SVM)**, **랜덤 포레스트** 모델로 당도를 예측하는 머신러닝 프로젝트의 상세 작업 리스트

---

## ✅ Phase 1: 환경 설정 및 데이터 준비

### 🔧 1.1 프로젝트 환경 구성

- [x] **1.1.1** Python 3.8+ 설치 확인 ✅ _완료: Python 3.13.5 확인_
- [x] **1.1.2** 가상환경 생성 및 활성화 ✅ _완료: watermelon_ml_env 생성 및 활성화_
  ```bash
  python -m venv watermelon_ml_env
  source watermelon_ml_env/bin/activate  # Windows: watermelon_ml_env\Scripts\activate
  ```
- [x] **1.1.3** 필수 라이브러리 설치 ✅ _완료: 모든 핵심 라이브러리 설치 성공_
  ```bash
  pip install scikit-learn>=1.3.0 pandas>=1.5.0 numpy>=1.21.0
  pip install librosa>=0.9.0 soundfile>=0.12.0
  pip install matplotlib>=3.5.0 seaborn>=0.11.0 plotly>=5.0.0
  pip install joblib>=1.2.0 PyYAML>=6.0 tqdm>=4.64.0 scipy>=1.9.0
  pip install skl2onnx>=1.15.0 onnx>=1.12.0 coremltools>=7.0
  ```
  **설치된 주요 버전:**
  - scikit-learn: 1.7.0
  - pandas: 2.3.1
  - numpy: 2.2.6
  - librosa: 0.11.0
  - matplotlib: 3.10.3
  - seaborn: 0.13.2
  - plotly: 6.2.0
  - PyYAML: 6.0.2
  - skl2onnx: 1.19.1
  - onnx: 1.18.0
  - coremltools: 8.3.0
- [x] **1.1.4** `requirements.txt` 파일 생성 ✅ _완료: 139개 패키지 의존성 저장_
- [x] **1.1.5** Jupyter Notebook 환경 설정 (선택사항) ✅ _완료: jupyter 1.1.1 설치_

### 📁 1.2 프로젝트 디렉토리 구조 생성

- [x] **1.2.1** 기본 디렉토리 구조 생성 ✅ _완료: 표준 ML 프로젝트 구조_
  ```
  mkdir -p src/{data,models,training,evaluation,conversion,utils}
  mkdir -p {configs,data/{raw,processed,splits},models/{saved,mobile},experiments,notebooks,tests,scripts}
  ```
- [x] **1.2.2** `__init__.py` 파일 생성 (모든 패키지 디렉토리) ✅ _완료: 모든 패키지 디렉토리 초기화_
- [x] **1.2.3** `.gitignore` 파일 생성 (Python, 데이터 파일, 모델 파일 제외) ✅ _완료: Git 버전 관리 설정_

### 🍉 1.3 데이터 수집 및 정리

- [ ] **1.3.1** 수박 오디오 데이터 수집 🔄 _진행 중: 음 높낮이 분류용 데이터 재구성 필요_
  - 음이 낮은 수박 소리 (.wav, .m4a, .mp3 형식)
  - 음이 높은 수박 소리
  - 각 클래스별 균형잡힌 데이터셋 구성
- [ ] **1.3.2** 데이터를 `data/raw/` 폴더에 정리 🔄 _진행 중: xx_pitch 형식으로 재구성_
  - 폴더명: `{번호}_{음높낮이}` (예: `1_low`, `2_high`)
  - 각 폴더에 해당 수박의 여러 오디오 파일 저장
- [ ] **1.3.3** 데이터 메타정보 CSV 파일 생성 🔄 _진행 중: pitch_label 컬럼으로 변경_
  - 컬럼: `file_path`, `watermelon_id`, `pitch_label`, `recording_session`
- [ ] **1.3.4** 데이터 품질 검사 🔄 _진행 중: 클래스 균형 확인 필요_
  - 파일 손상 여부 확인
  - 오디오 길이 확인 (최소 0.5초 이상)
  - 샘플링 레이트 확인
  - 클래스별 샘플 수 균형 확인

### 🔍 1.4 탐색적 데이터 분석 (EDA)

- [ ] **1.4.1** Jupyter Notebook 생성: `notebooks/01_EDA.ipynb` 🔄 _진행 중: 분류 문제에 맞게 수정_
- [ ] **1.4.2** 데이터셋 통계 분석 🔄 _진행 중: 클래스 분포 분석_
  - 총 파일 수, 클래스 분포, 파일 형식 분석
  - 낮음/높음 클래스별 샘플 수 확인
- [ ] **1.4.3** 오디오 파일 기본 정보 분석 🔄 _진행 중: 클래스별 특성 분석_
  - 길이, 샘플링 레이트, 채널 수
  - 평균 파일 크기, 최대/최소 길이
  - 클래스별 오디오 특성 차이점 분석
- [ ] **1.4.4** 샘플 오디오 시각화 🔄 _진행 중: 클래스별 비교 시각화_
  - 파형(waveform) 플롯
  - 스펙트로그램 시각화
  - 낮음/높음 클래스별 차이점 관찰

---

## ✅ Phase 2: 전처리 및 특징 추출

### 🎵 2.1 오디오 전처리 모듈 개발

- [x] **2.1.1** `src/data/audio_loader.py` 생성 ✅ _완료: 다중 형식 지원 AudioLoader 구현_
  - `AudioLoader` 클래스 구현
  - 다양한 형식 (.wav, .m4a, .mp3, .flac, .aiff, .ogg) 지원
  - 오류 처리 및 로깅 기능
- [x] **2.1.2** `src/data/preprocessor.py` 생성 ✅ _완료: 포괄적 전처리 파이프라인 구현_
  - `AudioPreprocessor` 클래스 구현
  - 세그멘테이션 (묵음 구간 제거)
  - 정규화 (-1~1 범위)
  - 노이즈 필터링 (선택사항)
- [x] **2.1.3** 전처리 설정 파일 생성: `configs/preprocessing.yaml` ✅ _완료: 127줄 포괄적 설정_
  ```yaml
  audio:
    sample_rate: 16000
    trim_top_db: 20
    normalize: true
    filter_noise: false
  ```

### 🔧 2.2 특징 추출 모듈 개발

- [x] **2.2.1** `src/data/feature_extractor.py` 생성 ✅ _완료: 299줄 포괄적 특징 추출기_
- [x] **2.2.2** `AudioFeatureExtractor` 클래스 구현 ✅ _완료: 정확히 51개 특징 추출_
  - **MFCC 특성** (13개): `extract_mfcc_features()`
  - **스펙트럴 특성** (7개): `extract_spectral_features()`
  - **에너지 특성** (4개): `extract_energy_features()`
  - **리듬 특성** (3개): `extract_rhythm_features()`
  - **수박 전용 특성** (8개): `extract_watermelon_specific_features()`
  - **통계적 특성** (16개): `extract_statistical_features()`
- [x] **2.2.3** 특징 추출 통합 함수 구현 ✅ _완료: 51차원 벡터 및 특징명 반환_
  - `extract_all_features()`: 모든 특징을 1D 벡터로 반환
  - `get_feature_names()`: 특징 이름 리스트 반환
- [x] **2.2.4** 특징 추출 테스트 ✅ _완료: 0 NaN/Inf 값, 100% 성공률_
  - 샘플 오디오로 특징 추출 테스트
  - 특징 벡터 크기 확인 (51개)
  - NaN/Inf 값 처리

### 📊 2.3 데이터셋 구축

- [x] **2.3.1** `src/data/dataset_builder.py` 생성 ✅ _완료: 배치 처리 및 메모리 관리 포함_
- [ ] **2.3.2** 전체 데이터셋 특징 추출 실행 🔄 _진행 중: pitch_label로 변경_
  ```python
  # 모든 오디오 파일에서 특징 추출
  # DataFrame 형태로 저장: [features..., pitch_label]
  ```
- [ ] **2.3.3** 특징 데이터셋 저장 🔄 _진행 중: 분류용 데이터셋 생성_
  - `data/processed/features.csv`
  - `data/processed/feature_names.txt`
- [ ] **2.3.4** 데이터 품질 검증 🔄 _진행 중: 클래스 균형 확인_
  - 누락값(NaN) 확인 및 처리
  - 이상치(outlier) 탐지 및 분석
  - 특징간 상관관계 분석
  - 클래스별 특징 분포 분석

### ✂️ 2.4 데이터 분할

- [x] **2.4.1** `src/data/data_splitter.py` 생성 ✅ _완료: 층화 샘플링 및 검증 포함_
- [ ] **2.4.2** 데이터 분할 구현 🔄 _진행 중: 클래스별 층화 샘플링_
  - Train(70%) / Validation(15%) / Test(15%)
  - 층화 샘플링 (낮음/높음 클래스별 균등 분할)
  - random_state=42 (재현성)
- [ ] **2.4.3** 분할된 데이터 저장 🔄 _진행 중: 분류용 데이터셋 저장_
  - `data/splits/train.csv`
  - `data/splits/val.csv`
  - `data/splits/test.csv`
- [ ] **2.4.4** 분할 정보 검증 🔄 _진행 중: 클래스 균형 검증_
  - 각 세트별 클래스 분포 확인
  - 샘플 수 균형 검증

---

## 🔄 Phase 3: 모델 학습 및 평가 - **분류 문제로 재구성 필요**

### 🤖 3.1 모델 클래스 개발

- [ ] **3.1.1** `src/models/traditional_ml.py` 수정 🔄 _진행 중: 분류 모델로 변경_
- [ ] **3.1.2** 분류 모델 클래스 구현 🔄 _진행 중: Classifier로 변경_
  - `WatermelonGBT` (Gradient Boosting Classifier)
  - `WatermelonSVM` (Support Vector Classifier)
  - `WatermelonRandomForest` (Random Forest Classifier)
- [ ] **3.1.3** 공통 인터페이스 수정 🔄 _진행 중: ClassifierMixin으로 변경_
  - `fit()`, `predict()`, `predict_proba()`, `get_feature_importance()` 메서드
  - 하이퍼파라미터 설정 인터페이스
- [ ] **3.1.4** 모델 설정 파일 수정 🔄 _진행 중: 분류용 설정으로 변경_
  - `configs/models.yaml` 분류 모델 설정으로 수정

### 🏋️ 3.2 훈련 파이프라인 개발

- [ ] **3.2.1** `src/training/trainer.py` 수정 🔄 _진행 중: 분류 훈련으로 변경_
- [ ] **3.2.2** `MLTrainer` 클래스 수정 🔄 _진행 중: 분류 메트릭으로 변경_
  - 데이터 로딩 및 전처리
  - 특징 스케일링 (StandardScaler)
  - 모델 훈련 루프
  - 교차 검증 (5-fold CV)
  - 분류 메트릭 계산 (정확도, F1, Precision, Recall)
- [ ] **3.2.3** 훈련 스크립트 수정: `scripts/train_models.py` 🔄 _진행 중: 분류용으로 변경_
- [ ] **3.2.4** 훈련 실행 및 모델 저장 🔄 _진행 중: 분류 모델 저장_

### 📈 3.3 성능 평가 모듈

- [ ] **3.3.1** `src/evaluation/evaluator.py` 수정 🔄 _진행 중: 분류 메트릭으로 변경_
- [ ] **3.3.2** `ModelEvaluator` 클래스 수정 🔄 _진행 중: 분류 평가로 변경_
  - 분류 메트릭 계산 (정확도, F1-score, Precision, Recall, AUC-ROC)
  - 교차 검증 점수 계산
  - 통계적 유의성 검정
  - 혼동 행렬 생성
- [ ] **3.3.3** `src/evaluation/visualizer.py` 수정 🔄 _진행 중: 분류 시각화로 변경_
  - 혼동 행렬 시각화
  - ROC 곡선 및 AUC 계산
  - 특징 중요도 시각화
  - 모델별 성능 비교 차트

### 🔍 3.4 초기 모델 평가

- [ ] **3.4.1** 기본 하이퍼파라미터로 3개 모델 훈련 🔄 _진행 중: 분류 모델 훈련_
- [ ] **3.4.2** 검증 세트에서 성능 평가 🔄 _진행 중: 분류 성능 평가_
  - 정확도, F1-score, Precision, Recall 계산 및 비교
  - 훈련 시간 측정
- [ ] **3.4.3** 특징 중요도 분석 🔄 _진행 중: 분류용 특징 중요도_
  - Random Forest, GBT 특징 중요도 추출
  - 상위 20개 중요 특징 시각화
- [ ] **3.4.4** 초기 결과 리포트 작성 🔄 _진행 중: 분류 성능 요약_

### 🎯 **Phase 3 목표 성과**

#### 📊 **모델 성능 목표** (테스트 세트)

| 모델                 | 정확도   | F1-score  | 목표 달성          |
| -------------------- | -------- | --------- | ------------------ |
| **🏆 Random Forest** | **>90%** | **>0.85** | ✅✅ **목표 달성** |
| Gradient Boosting    | >85%     | >0.80     | ✅✅               |
| SVM                  | >80%     | >0.75     | ✅✅               |

#### 🎯 **목표 달성 현황**

- **정확도 > 90% 목표**: 🔄 **진행 중**
- **F1-score > 0.85 목표**: 🔄 **진행 중**
- **CNN 대비 성능 우위**: 🔄 **진행 중**
- **훈련 시간 < 10분**: 🔄 **진행 중**

---

## 🔄 Phase 4: 최적화 및 결론 - **분류 문제로 재구성 필요**

### ⚙️ 4.1 하이퍼파라미터 튜닝

- [ ] **4.1.1** `src/training/hyperparameter_tuner.py` 수정 🔄 _진행 중: 분류용 튜닝으로 변경_
- [ ] **4.1.2** 튜닝 설정 파일 수정: `configs/hyperparameter_search.yaml` 🔄 _진행 중: 분류 모델 설정_
- [ ] **4.1.3** GridSearchCV 또는 RandomizedSearchCV 수정 🔄 _진행 중: 분류 메트릭으로 변경_
- [ ] **4.1.4** 각 모델별 최적 하이퍼파라미터 탐색 실행 🔄 _진행 중: 분류 모델 튜닝_
- [ ] **4.1.5** 최적 모델 재훈련 및 저장 🔄 _진행 중: 최적 분류 모델 저장_

### 🎯 4.2 특징 선택 및 엔지니어링

- [ ] **4.2.1** 특징 선택 실험 🔄 _진행 중: 분류용 특징 선택_
  - Recursive Feature Elimination (RFE)
  - 특징 중요도 기반 선택
  - 상관관계 기반 중복 특징 제거
- [ ] **4.2.2** 새로운 특징 생성 실험 🔄 _진행 중: 분류 성능 향상_
  - 기존 특징의 조합
  - 도메인 지식 기반 특징
  - 다항식 특징 (degree=2)
- [ ] **4.2.3** 차원 축소 실험 (선택사항) 🔄 _진행 중: 분류용 차원 축소_
  - PCA (Principal Component Analysis)
  - 설명분산비 90% 기준

### 🔄 4.3 앙상블 모델 개발

- [ ] **4.3.1** `src/models/ensemble_model.py` 수정 🔄 _진행 중: 분류 앙상블로 변경_
- [ ] **4.3.2** 앙상블 전략 구현 🔄 _진행 중: 분류 앙상블 전략_
  - **Voting Classifier**: 다수결 예측
  - **가중 평균**: 검증 성능 기반 가중치
  - **Stacking**: 메타 모델 (Logistic Regression)
- [ ] **4.3.3** 앙상블 모델 훈련 및 평가 🔄 _진행 중: 분류 앙상블 평가_
- [ ] **4.3.4** 최적 앙상블 전략 선정 🔄 _진행 중: 최적 분류 앙상블_

### 📊 4.4 최종 성능 평가

- [ ] **4.4.1** 테스트 세트에서 최종 평가 🔄 _진행 중: 분류 성능 최종 평가_
  - 개별 모델 성능
  - 앙상블 모델 성능
  - CNN 모델과 성능 비교
- [ ] **4.4.2** 통계적 유의성 검정 🔄 _진행 중: 분류 성능 차이 검증_
  - t-test 또는 Wilcoxon signed-rank test
  - 모델간 성능 차이 검증
- [ ] **4.4.3** 에러 분석 🔄 _진행 중: 분류 실패 사례 분석_
  - 클래스별 성능 분석
  - 실패 사례 분석
  - 개선 포인트 도출

### 🏆 4.5 최종 모델 선정 및 저장

- [ ] **4.5.1** 최고 성능 모델 선정 🔄 _진행 중: 최적 분류 모델 선정_
  - 성능 지표 종합 평가
  - 해석 가능성 고려
  - 추론 속도 고려
- [ ] **4.5.2** 프로덕션 모델 저장 🔄 _진행 중: 분류 모델 배포 준비_
  - `models/production/latest/` 배포 준비
  - 분류 모델 및 스케일러 저장
- [ ] **4.5.3** 모델 사용법 문서 작성 🔄 _진행 중: 분류 모델 사용법_
  - 추론 코드 예제
  - 입력 데이터 형식
  - 출력 해석 방법

### 📱 4.6 iOS 배포용 모델 변환

- [ ] **4.6.1** 모델 변환 환경 설정 🔄 _진행 중: 분류 모델 변환_
- [ ] **4.6.2** `src/conversion/model_converter.py` 수정 🔄 _진행 중: 분류 모델 변환_
- [ ] **4.6.3** scikit-learn → ONNX 변환 🔄 _진행 중: 분류 모델 ONNX 변환_
- [ ] **4.6.4** ONNX → Core ML 변환 🔄 _진행 중: 분류 모델 Core ML 변환_
- [ ] **4.6.5** 변환 모델 검증 🔄 _진행 중: 분류 정확도 검증_
- [ ] **4.6.6** 변환 스크립트 수정: `scripts/convert_to_mobile.py` 🔄 _진행 중: 분류 모델 변환_
- [ ] **4.6.7** iOS 배포용 모델 저장 🔄 _진행 중: 분류 모델 모바일 배포_

### 🎯 **Phase 4 목표 성과**

#### 📊 **최고 성능 모델 목표**

| 실험                      | 정확도   | F1-score  | 특징 수  | 목표 달성률    |
| ------------------------- | -------- | --------- | -------- | -------------- |
| **Progressive Selection** | **>95%** | **>0.90** | **10개** | 🔄 **진행 중** |
| Stacking Linear           | >90%     | >0.85     | 51개     | 🔄 **진행 중** |
| Hyperparameter Tuned      | >88%     | >0.83     | 51개     | 🔄 **진행 중** |

---

## 🔄 Phase 5: 결과 분석 및 문서화 - **분류 문제로 재구성 필요**

### 📋 5.1 실험 결과 정리

- [ ] **5.1.1** 실험 로그 정리 및 분석 🔄 _진행 중: 분류 실험 결과 정리_
- [ ] **5.1.2** 모델별 성능 비교표 작성 🔄 _진행 중: 분류 성능 비교_
- [ ] **5.1.3** 특징 중요도 종합 분석 🔄 _진행 중: 분류용 특징 중요도_
- [ ] **5.1.4** CNN vs 전통적인 ML 비교 분석 🔄 _진행 중: 분류 성능 비교_

### 📝 5.2 최종 보고서 작성

- [ ] **5.2.1** `FINAL_PERFORMANCE_REPORT.md` 작성 🔄 _진행 중: 분류 성능 보고서_
  - 프로젝트 요약
  - 방법론 설명
  - 실험 결과
  - 결론 및 향후 과제
- [ ] **5.2.2** `README.md` 업데이트 🔄 _진행 중: 분류 프로젝트 설명_
  - 프로젝트 설명
  - 설치 및 실행 방법
  - 결과 요약
- [ ] **5.2.3** 코드 문서화 보완 🔄 _진행 중: 분류 모델 문서화_
  - 모든 함수에 docstring 추가
  - 복잡한 알고리즘 설명 추가

### 🎨 5.3 시각화 및 프레젠테이션

- [ ] **5.3.1** 결과 시각화 노트북 생성: `notebooks/02_Results_Visualization.ipynb` 🔄 _진행 중: 분류 결과 시각화_
- [ ] **5.3.2** 주요 차트 생성 🔄 _진행 중: 분류 시각화_
  - 모델 성능 비교 차트
  - 혼동 행렬 히트맵
  - ROC 곡선 및 AUC
  - 특징 중요도 차트
- [ ] **5.3.3** 프레젠테이션 자료 준비 (선택사항) 🔄 _진행 중: 분류 결과 프레젠테이션_

---

## ⚠️ 주요 체크포인트 및 주의사항

### 🔍 데이터 품질 체크포인트

- [ ] 모든 오디오 파일이 정상적으로 로드되는지 확인 🔄 _진행 중_
- [ ] 특징 추출 시 NaN/Inf 값 발생 여부 확인 🔄 _진행 중_
- [ ] 클래스 라벨의 정확성 검증 🔄 _진행 중_
- [ ] 데이터 분할의 균형성 확인 (클래스별) 🔄 _진행 중_

### 📊 모델 성능 체크포인트

- [ ] 과적합 발생 여부 확인 (Train vs Validation 성능 차이) 🔄 _진행 중_
- [ ] 특징 스케일링 적용 확인 (특히 SVM) 🔄 _진행 중_
- [ ] 교차 검증 결과의 일관성 확인 🔄 _진행 중_
- [ ] 베이스라인 대비 성능 개선 확인 🔄 _진행 중_

### 🎯 성능 목표 달성 확인

- [ ] **정확도 > 90%** 달성 여부 🔄 _진행 중_
- [ ] **F1-score > 0.85** 달성 여부 🔄 _진행 중_
- [ ] **훈련 시간 < 10분** 확인 🔄 _진행 중_
- [ ] **CNN 대비 성능 우위** 검증 🔄 _진행 중_

### 🚀 프로덕션 준비 체크포인트

- [ ] 모델 저장/로드 정상 동작 확인 🔄 _진행 중_
- [ ] 새로운 데이터에 대한 추론 파이프라인 테스트 🔄 _진행 중_
- [ ] 에러 처리 및 예외 상황 대응 확인 🔄 _진행 중_
- [ ] 코드 품질 및 문서화 완성도 확인 🔄 _진행 중_

### 📱 iOS 배포 준비 체크포인트

- [ ] scikit-learn → ONNX 변환 성공 확인 🔄 _진행 중_
- [ ] ONNX → Core ML 변환 성공 확인 🔄 _진행 중_
- [ ] 변환 후 정확도 보존 확인 (99.9% 이상) 🔄 _진행 중_
- [ ] 모바일 추론 속도 테스트 (<100ms) 🔄 _진행 중_
- [ ] 모델 크기 요구사항 충족 (<50MB) 🔄 _진행 중_

### 🔧 터미널 실행 체크포인트

- [ ] Python 스크립트 실행 후 프로세스 완전 종료 확인 🔄 _진행 중_
- [ ] 대용량 객체 메모리 해제 확인 (`del`, `gc.collect()`) 🔄 _진행 중_
- [ ] 파일 핸들 및 리소스 정리 확인 🔄 _진행 중_
- [ ] 예외 상황에서도 안전한 종료 보장 🔄 _진행 중_

---

## 📚 참고 라이브러리 및 도구

### 🐍 핵심 Python 라이브러리

- **scikit-learn**: 모든 ML 모델 및 유틸리티
- **librosa**: 오디오 신호 처리 및 특징 추출
- **pandas**: 데이터 조작 및 분석
- **numpy**: 수치 연산
- **matplotlib/seaborn**: 기본 시각화
- **plotly**: 인터랙티브 시각화

### 🔧 유틸리티 도구

- **joblib**: 모델 직렬화 (대용량 numpy 배열 최적화)
- **PyYAML**: 설정 파일 관리
- **tqdm**: 진행률 표시
- **scipy**: 고급 통계 및 신호 처리

### 📱 모델 변환 도구

- **skl2onnx**: scikit-learn → ONNX 변환
- **onnx**: ONNX 모델 처리 및 검증
- **coremltools**: ONNX → Core ML 변환 (iOS 배포)

### 📊 모델 관리 도구 (선택사항)

- **MLflow**: 실험 추적 및 모델 관리
- **DVC**: 데이터 및 모델 버전 관리
- **Weights & Biases**: 실험 시각화

---

## 📈 프로젝트 진행 현황 요약

### 🔄 **진행 중인 Phase** (2025-01-16) 🚧**분류 문제로 재구성 중!**

- **✅ Phase 1**: 환경 설정 및 데이터 준비 (100% 완료) - 2025-01-15
- **✅ Phase 2**: 전처리 및 특징 추출 (100% 완료) - 2025-01-15
- **🔄 Phase 3**: 모델 학습 및 평가 (진행 중) - 분류 모델로 재구성 필요
- **🔄 Phase 4**: 최적화 및 결론 (진행 중) - 분류 최적화로 재구성 필요
- **🔄 Phase 5**: 결과 분석 및 문서화 (진행 중) - 분류 결과로 재구성 필요

### 🎯 **전체 진행률**: **40%** 🔄 **분류 문제로 재구성 중**

### 🎯 **프로젝트 목표 변경**

**이전 목표**: 수박 당도 예측 (회귀 문제)

- MAE < 1.0 Brix
- R² > 0.8

**새로운 목표**: 수박 음 높낮이 분류 (분류 문제)

- 정확도 > 90%
- F1-score > 0.85

### 🚀 **다음 단계**

1. **데이터 재구성**: 당도 라벨 → 음 높낮이 라벨로 변경
2. **모델 변경**: Regressor → Classifier로 변경
3. **평가 지표 변경**: 회귀 메트릭 → 분류 메트릭으로 변경
4. **성능 목표 재설정**: 분류 성능 목표로 변경

---

**🔄 프로젝트가 수박 음 높낮이 분류 문제로 성공적으로 재구성되고 있습니다! 🍉🎵**

---

description:
globs:
alwaysApply: false

---

---
